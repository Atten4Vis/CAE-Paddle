# UFO

- [ALL in one](#AllinOne)
  * [UFO整体架构](#图1:UFO整体架构)
  * [单模型覆盖智慧城市4大任务](#单模型覆盖智慧城市4大任务)
  * [任务设置与数据](#任务设置与数据)
  * [统一各任务配置](#统一各任务的配置)
  * [多任务异构数据采样策略和DropPath正则技术](#多任务异构数据采样策略和DropPath正则技术)
  * [单模型刷新10项公开数据集SOTA结果](#单模型刷新10项公开数据集SOTA结果)

百度提出统一特征表示优化技术（UFO：Unified Feature Optimization），在充分利用大数据和大模型的同时，兼顾大模型落地成本及部署效率。UFO技术方案的主要内容包括：
  * All in one：设计视觉表示多任务协同训练方案，免去了下游任务fine-tuning的过程，实现单模型在智慧城市多个核心任务效果全面领先
  * One for all：首创针对视觉多任务的超网络与训练方案，支持各类任务、各类硬件的灵活部署，解决大模型推理性能差的问题。
![图1:UFO整体架构](./img/fig1.png)
## 图1:UFO整体架构

## AllinOne：功能更强大、更通用的视觉模型	

之前主流的视觉模型生产流程，通常采用单任务 “train from scratch”方案。每个任务都从零开始训练，各个任务之间也无法相互借鉴。由于单任务数据不足带来偏置问题，实际效果过分依赖任务数据分布，场景泛化效果往往不佳。近两年蓬勃发展的大数据预训练技术，通过使用大量数据学到更多的通用知识，然后迁移到下游任务当中，本质上是不同任务之间相互借鉴了各自学到的知识。基于海量数据获得的预训练模型具有较好的知识完备性，在下游任务中基于少量数据fine-tuning依然可以获得较好的效果。不过基于预训练+下游任务fine-tuning的模型生产流程，需要针对各个任务分别训练模型，存在较大的研发资源消耗。

百度提出的UFO All in One模型，通过使用多个任务的数据训练一个功能强大的通用模型，可被直接应用于处理多个任务。不仅通过跨任务的信息提升了单个任务的效果，并且免去了下游任务fine-tuning过程。UFO All in One模型研发模式可被广泛应用于各类多任务AI系统，以智慧城市的多任务大模型为例，UFO All in One可以用单模型实现多个任务的SOTA识别效果，同时多任务模型可获得显著优于单任务模型的效果，证明了多任务之间信息借鉴机制的有效性。

### 单模型覆盖智慧城市4大任务

智慧城市是目前计算机视觉技术最重要的应用场景之一，在智慧城市的各个任务中，往往要同时处理人脸、人体、车辆和通用物体等目标，这对AI系统的多任务协同能力提出了非常高的要求。现有的视觉模型大多只能检测或识别其中的一类目标，百度通过UFO方案中的多任务协同学习技术，产出城市视觉UFO模型同时处理这4类任务，并在10项公开数据集上效果取得SOTA。下面详细介绍UFO的多任务协同训练方案。

### 任务设置与数据

为验证方案的有效性且便于公平对比，使用10项公开数据集进行训练和测试。各个数据集的统计信息如表所示：

### 训练集

| **任务**                      | **数据集**                     | **图片数**                     | **类别数**                     |
| :-----------------------------| :----------------------------: | :----------------------------: | :----------------------------: |
| 人脸                          |           MS1M-V3              |           5,179,510            |           93,431               |
| 人体                          |           Market1501-Train     |           12,936               |           751                  |
| 人体                          |           DukeMTMC-Train       |           16,522               |           702                  |
| 人体                          |           MSMT17-Train         |           30,248               |           1,041                |
| 车辆                          |           Veri-776-Train       |           37,778               |           576                  |
| 车辆                          |           VehicleID-Train      |           113,346              |           13,164               |
| 车辆                          |           VeriWild-Train       |           277,797              |           30,671               |
| 商品                          |           SOP-Train            |           59,551               |           11,318               |


### 测试集

| **任务**                      | **数据集**                     | **图片数**                     | **类别数**                     |
| :-----------------------------| :----------------------------: | :----------------------------: | :----------------------------: |
| 人脸                          |           LFW                  |           12,000               |           -                    |
| 人脸                          |           CPLFW                |           12,000               |           -                    |
| 人脸                          |           CFP-FF               |           14,000               |           -                    |
| 人脸                          |           CFP-FP               |           14,000               |           -                    |
| 人脸                          |           CALFW                |           12,000               |           -                    |
| 人脸                          |           AGEDB-30             |           12,000               |           -                    |
| 人体                          |           Market1501-Test      |           19,281               |           750                  |
| 人体                          |           DukeMTMC-Test        |           19,889               |           702                  |
| 人体                          |           MSMT17-Test          |           93,820               |           3,060                |
| 车辆                          |           Veri-776-Test        |           13,257               |           200                  |
| 车辆                          |           VehicleID-Test       |           19,777               |           2,400                |
| 车辆                          |           VeriWild-Test        |           138,517              |           10,000               |
| 商品                          |           SOP-Test             |           60,502               |           11,316               |

### 统一各任务的配置

从模型优化的层面来说，以往不同任务模型训练的batch size 、学习率乃至于优化器都各不相同。为了方便后续的多任务训练，UFO方案统一了各个任务的模型结构以及优化方法。任务配置如下表所示：

|                               |        **人脸**/ **人体**/**商品**/**车辆**          |
| :-----------------------------| :----------------------------------------------------|
| 输入大小                      |    384 × 384                                         |
| Batch Size                    |    1024/512/512/512                                  |
| 数据增强                      |    Flipping + Random Erasing + AutoAug               |
| 模型结构                      |    ViT-Large                                         |
| 输出特征维度                  |    1024                                              |
| 损失函数                      |    CosFace Loss/(CosFace Loss + Triplet Loss)*3      |
| 优化器                        |    SGD                                               |
| 初始学习率                    |    0.2                                               |
| LR scheduler                  |    Warmup + Cosine LR                                |
| 迭代次数                      |    100,000                                           |

### 多任务异构数据采样策略和DropPath正则技术

多任务学习首先面临的问题是如何构建 Batch。常用的方式有两种，一种是同数据域的 Batch 组成，即 Batch 内的数据均来自同一个任务，通过不同的 Batch 选择不同的任务来保证训练所有任务。另一种是不同数据域的 Batch 组成，即Batch 内的数据来自不同的任务。同数据域的 Batch 组成面临的问题是当模型中使用 Batch Norm 这一常见的操作时，因为训练时的统计值（单任务统计值）和测试时的统计值（多任务统计值）差异较大，导致模型效果较差。如下表所示，通过ResNet50结构在人体 Market1501 和物品SOP两个任务中验证，使用混合数据域方案可以大幅提高两任务的效果。

|    Batch 数据混合    |         Market1501 (rank1/mAP)    |        SOP (rank1)        |
| :--------------------| :--------------------------------:|:-------------------------:|
|  同构                |           73.13 / 50.58           |          79.54            |
|  异构                |           94.27 / 85.77           |          85.76            |

在四个任务中，人体和物品的训练集数量最小，都只有 6 万张图片左右，而人脸和车辆则各有约 500 万和 40  万张图片。因此在多任务训练过程中，呈现出了人体、物品快速过拟合，而人脸和车辆欠拟合的现象。为解决各个任务数据不均衡导致的过拟合问题，通过在训练过程中使用 Drop Path 正则化方法，在人体和物品任务中实现mAP1%~3%的提升，同时其他任务效果持平或更好。

### 单模型刷新10项公开数据集SOTA结果
 
基于多任务协同训练方案得到的城市视觉 All in One UFO模型，和之前的单任务SOTA 结果相比，在 4 个任务的10个测试集上都达到了新的SOTA，同时相比使用同样模型结构的单任务结果，在多数任务上UFO也表现的更好，证明了多任务之间信息借鉴机制的有效性。

![图2:10项公开数据集SOTA结果](./img/fig2.png)
## 图2:10项公开数据集SOTA结果

在上图中，灰色表示表示城市视觉 All in One UFO模型的结果，橙色表示和UFO模型使用相同模型结构的单任务结果，蓝色表示之前同样数据集上最优的单任务结果。以上所有结果都不使用预训练数据，同时无重排序策略。
